---
layout: single
title: "크롤링"
categories: blog
tag: [github, spring, eclipse]
toc: true
author_profile: false
sidebar:
  nav: "docs"
typora-root-url: ../
---



```python
import requests
from bs4 import BeautifulSoup
res = requests.get('http://v.media.daum.net/v/20170615203441266')
soup = BeautifulSoup(res.content, 'html.parser')
mydata = soup.find('title')
print(mydata.get_text())
```

```
잔금대출에도 DTI 규제 적용 검토
```



```python
import requests
from bs4 import BeautifulSoup
```


```python
res = requests.get('http://v.media.daum.net/v/20170615203441266')
res.content
```

## IP Address: ex) 123.123.11.22


```python
res = requests.get('http://v.media.daum.net/v/20170615203441266')
res.content
```


```python
soup = BeautifulSoup(res.content, 'html.parser')
soup
```


```python
soup.find('h3')
```




    <h3 class="tit_view" data-translation="true">잔금대출에도 DTI 규제 적용 검토</h3>




```python
mydata = soup.find('h3')
```


```python
mydata.get_text()
```




    '잔금대출에도 DTI 규제 적용 검토'




```python
from bs4 import BeautifulSoup
html = """
<html> 
<body> 
<h1 id='title'>[1]크롤링이란?</h1> 
<p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p> 
<p id='body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p> 
</body> 
</html>
"""
soup = BeautifulSoup(html, "html.parser")
# 태그로 검색 방법
data = soup.find('h1')
print(data)
print(data.string)
print(data.get_text())
```

    <h1 id="title">[1]크롤링이란?</h1>
    [1]크롤링이란?
    [1]크롤링이란?


1. data = soup.find('p', class_='cssstyle')
2. data = soup.find('p', 'cssstyle')
3. data = soup.find('p', attrs = {'align': 'center'})
4. data = soup.find(id='body')


```python
data = soup.find('p', class_ ='cssstyle')
print(data.string)
```

    웹페이지에서 필요한 데이터를 추출하는 것



```python
data = soup.find('p', attrs={'id':'body', 'align':'center'})
print(data.string)
```

    파이썬을 중심으로 다양한 웹크롤링 기술 발달



```python
data= soup.find_all('p')
for item in data: 
    print (item.string)
```

    웹페이지에서 필요한 데이터를 추출하는 것
    파이썬을 중심으로 다양한 웹크롤링 기술 발달



```python
mydata = soup.find('h3', 'tit_view')
mydata.get_text()
```




    '잔금대출에도 DTI 규제 적용 검토'




```python
mydata = soup.find_all("span", 'txt_info')
for i in mydata:
    print(i.get_text())
```

    김동욱
    입력 2017. 6. 15. 20:34
    수정 2017. 6. 15. 21:31



```python
mydata[1].get_text()
```




    '입력 2017. 6. 15. 20:34'




```python
mydata = soup.find('div', 'inner_view_layer inner_translate_layer')
mydata.get_text()
```




    '\n 번역beta Translated by kaka i\n\n\n\n  한국어 -  \n  English 영어  \n  日本語 일본어  \n  简体中文 중국어  \n  Nederlands 네델란드어  \n  Deutsch 독일어  \n  Русский 러시아어  \n  Malaysia 말레이시아어  \n  বাঙ্গোল ভাষা 벵골어  \n  tiếng Việt 베트남어  \n  Español 스페인어  \n  اللغة العربية 아랍어  \n  Italiano 이탈리아어  \n  bahasa Indonesia 인도네시아어  \n  ภาษาไทย 태국어  \n  Türkçe 터키어  \n  Português 포르투갈어  \n  Français 프랑스어  \n  हिन्दी 힌디어  \n\n\n  닫기 \n\n'



# _크롤링 후처리_
* \n, 불필요한 데이터 삭제, 깔끔하게 문자열 정리
