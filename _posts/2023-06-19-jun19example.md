---
layout: single
title: "Example (Keras & nltk)"
categories: python
tag: [colab, ai]
toc: true
author_profile: false
sidebar:
  nav: "docs"
typora-root-url: ../
---

```python
text = """What’s this? What’s this?
What’s this? What? What?
It’s a cap. It’s a cap. It’s a cap, cap, cap.
What’s this? What’s this?
What’s this? What? What?
It’s a ball. It’s a ball. It’s a ball, ball, ball.
I’m a little teapot, Short and stout.
This is my handle, This is my spout.
When the water’s boiling, give a shout.
Tip me over and pour me out.
Butterfly, Butterfly
Come and fly on over here
Yellow and white butterfly
Come and dance on over here.
On a windy springtime day
Petals smile in the wind
Sparrows, too chirp chirp chirp
Sing a song and dance along
Three fuzzy bears live in one house
Daddy bear, Mommy bear, Baby bear
Daddy bear is big and fat
Mommy bear is slim and trim
Baby bear is such a cutie pie
Tee-hee Tee-hee, There you go"""
text
```

```python
# 주어진 글에 엔터부분을 띄어쓰기로 고치고
# 띄어쓰기를 기준으로 단어를 나누 후에 => 문장 토큰화를 진행하고 
# keras를 이용해서 각 단어에 인덱스를 부여하기 
text = text.replace("\n", " ")
texts = text.split(" ")
texts
```

```
['What’s',
 'this?',
 'What’s',
 'this?',
 'What’s',
 'this?',
 'What?',
 'What?',
 'It’s',
 'a',
 'cap.',
 'It’s',
 'a',
 'cap.',
 'It’s',
 'a',
 'cap,',
 'cap,',
 'cap.',
 'What’s',
 'this?',
 'What’s',
 'this?',
 'What’s',
 'this?',
 'What?',
 'What?',
 'It’s',
 'a',
 'ball.',
 'It’s',
 'a',
 'ball.',
 'It’s',
 'a',
 'ball,',
 'ball,',
 'ball.',
 'I’m',
 'a',
 'little',
 'teapot,',
 'Short',
 'and',
 'stout.',
 'This',
 'is',
 'my',
 'handle,',
 'This',
 'is',
 'my',
 'spout.',
 'When',
 'the',
 'water’s',
 'boiling,',
 'give',
 'a',
 'shout.',
 'Tip',
 'me',
 'over',
 'and',
 'pour',
 'me',
 'out.',
 'Butterfly,',
 'Butterfly',
 'Come',
 'and',
 'fly',
 'on',
 'over',
 'here',
 'Yellow',
 'and',
 'white',
 'butterfly',
 'Come',
 'and',
 'dance',
 'on',
 'over',
 'here.',
 'On',
 'a',
 'windy',
 'springtime',
 'day',
 'Petals',
 'smile',
 'in',
 'the',
 'wind',
 'Sparrows,',
 'too',
 'chirp',
 'chirp',
 'chirp',
 'Sing',
 'a',
 'song',
 'and',
 'dance',
 'along',
 'Three',
 'fuzzy',
 'bears',
 'live',
 'in',
 'one',
 'house',
 'Daddy',
 'bear,',
 'Mommy',
 'bear,',
 'Baby',
 'bear',
 'Daddy',
 'bear',
 'is',
 'big',
 'and',
 'fat',
 'Mommy',
 'bear',
 'is',
 'slim',
 'and',
 'trim',
 'Baby',
 'bear',
 'is',
 'such',
 'a',
 'cutie',
 'pie',
 'Tee-hee',
 'Tee-hee,',
 'There',
 'you',
 'go']
```

```python
from tensorflow.keras.preprocessing.text import Tokenizer
tokenizer = Tokenizer()
tokenizer.fit_on_texts(texts)
print(tokenizer.word_index)
```

```
{'a': 1, 'this': 2, 'and': 3, 'what’s': 4, 'it’s': 5, 'bear': 6, 'cap': 7, 'ball': 8, 'is': 9, 'what': 10, 'over': 11, 'butterfly': 12, 'on': 13, 'chirp': 14, 'my': 15, 'the': 16, 'me': 17, 'come': 18, 'here': 19, 'dance': 20, 'in': 21, 'daddy': 22, 'mommy': 23, 'baby': 24, 'tee': 25, 'hee': 26, 'i’m': 27, 'little': 28, 'teapot': 29, 'short': 30, 'stout': 31, 'handle': 32, 'spout': 33, 'when': 34, 'water’s': 35, 'boiling': 36, 'give': 37, 'shout': 38, 'tip': 39, 'pour': 40, 'out': 41, 'fly': 42, 'yellow': 43, 'white': 44, 'windy': 45, 'springtime': 46, 'day': 47, 'petals': 48, 'smile': 49, 'wind': 50, 'sparrows': 51, 'too': 52, 'sing': 53, 'song': 54, 'along': 55, 'three': 56, 'fuzzy': 57, 'bears': 58, 'live': 59, 'one': 60, 'house': 61, 'big': 62, 'fat': 63, 'slim': 64, 'trim': 65, 'such': 66, 'cutie': 67, 'pie': 68, 'there': 69, 'you': 70, 'go': 71}

```

```python
# nltk에서 제공하는 불용어를 다운로드 한 후에 처음에 사용한 글을 문장 기준으로 나눈 후
# 모든 단어를 소문자로 교체한 후에 두글자 이하인 단어는 제거하고,
# 불용어에 해당하는 단어도 제거하기 ! 
import nltk 
from nltk.tokenize import sent_tokenize
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

nltk.download('stopwords')
nltk.download('punkt')
```

```
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
True
```

```python
sentence = sent_tokenize(text)
print(sentence)
```

```
['What’s this?', 'What’s this?', 'What’s this?', 'What?', 'What?', 'It’s a cap.', 'It’s a cap.', 'It’s a cap, cap, cap.', 'What’s this?', 'What’s this?', 'What’s this?', 'What?', 'What?', 'It’s a ball.', 'It’s a ball.', 'It’s a ball, ball, ball.', 'I’m a little teapot, Short and stout.', 'This is my handle, This is my spout.', 'When the water’s boiling, give a shout.', 'Tip me over and pour me out.', 'Butterfly, Butterfly Come and fly on over here Yellow and white butterfly Come and dance on over here.', 'On a windy springtime day Petals smile in the wind Sparrows, too chirp chirp chirp Sing a song and dance along Three fuzzy bears live in one house Daddy bear, Mommy bear, Baby bear Daddy bear is big and fat Mommy bear is slim and trim Baby bear is such a cutie pie Tee-hee Tee-hee, There you go']

```

```python
sw = set(stopwords.words('english'))

aa = {}
fs = []

for s in sentence:
  word = word_tokenize(s)
  result = []
  for w in word:
    w = w.lower()
    if w not in sw:
      if len(w) > 2:
        result.append(w)
        if w not in aa:
          aa[w] = 0
        aa[w] += 1
  fs.append(result)

print(fs)
print(aa)
```

```
[[], [], [], [], [], ['cap'], ['cap'], ['cap', 'cap', 'cap'], [], [], [], [], [], ['ball'], ['ball'], ['ball', 'ball', 'ball'], ['little', 'teapot', 'short', 'stout'], ['handle', 'spout'], ['water', 'boiling', 'give', 'shout'], ['tip', 'pour'], ['butterfly', 'butterfly', 'come', 'fly', 'yellow', 'white', 'butterfly', 'come', 'dance'], ['windy', 'springtime', 'day', 'petals', 'smile', 'wind', 'sparrows', 'chirp', 'chirp', 'chirp', 'sing', 'song', 'dance', 'along', 'three', 'fuzzy', 'bears', 'live', 'one', 'house', 'daddy', 'bear', 'mommy', 'bear', 'baby', 'bear', 'daddy', 'bear', 'big', 'fat', 'mommy', 'bear', 'slim', 'trim', 'baby', 'bear', 'cutie', 'pie', 'tee-hee', 'tee-hee']]
{'cap': 5, 'ball': 5, 'little': 1, 'teapot': 1, 'short': 1, 'stout': 1, 'handle': 1, 'spout': 1, 'water': 1, 'boiling': 1, 'give': 1, 'shout': 1, 'tip': 1, 'pour': 1, 'butterfly': 3, 'come': 2, 'fly': 1, 'yellow': 1, 'white': 1, 'dance': 2, 'windy': 1, 'springtime': 1, 'day': 1, 'petals': 1, 'smile': 1, 'wind': 1, 'sparrows': 1, 'chirp': 3, 'sing': 1, 'song': 1, 'along': 1, 'three': 1, 'fuzzy': 1, 'bears': 1, 'live': 1, 'one': 1, 'house': 1, 'daddy': 2, 'bear': 6, 'mommy': 2, 'baby': 2, 'big': 1, 'fat': 1, 'slim': 1, 'trim': 1, 'cutie': 1, 'pie': 1, 'tee-hee': 2}

```

```python
# 원래의 list는 그대로 두고, 새로운 dict를 작성해서 정렬한 후에 
# 더 높은 빈도수를 가지고 있는 단어부터 낮은 정수값을 부여하기 ! 
aaSort = sorted(aa.items(), key=lambda x:x[1], reverse=True)
aaSort
```

```
[('bear', 6),
 ('cap', 5),
 ('ball', 5),
 ('butterfly', 3),
 ('chirp', 3),
 ('come', 2),
 ('dance', 2),
 ('daddy', 2),
 ('mommy', 2),
 ('baby', 2),
 ('tee-hee', 2),
 ('little', 1),
 ('teapot', 1),
 ('short', 1),
 ('stout', 1),
 ('handle', 1),
 ('spout', 1),
 ('water', 1),
 ('boiling', 1),
 ('give', 1),
 ('shout', 1),
 ('tip', 1),
 ('pour', 1),
 ('fly', 1),
 ('yellow', 1),
 ('white', 1),
 ('windy', 1),
 ('springtime', 1),
 ('day', 1),
 ('petals', 1),
 ('smile', 1),
 ('wind', 1),
 ('sparrows', 1),
 ('sing', 1),
 ('song', 1),
 ('along', 1),
 ('three', 1),
 ('fuzzy', 1),
 ('bears', 1),
 ('live', 1),
 ('one', 1),
 ('house', 1),
 ('big', 1),
 ('fat', 1),
 ('slim', 1),
 ('trim', 1),
 ('cutie', 1),
 ('pie', 1)]
```

```python
aaIndex = {}
i = 0

for word,count in aaSort:
  if count > 1:
    i += 1
    aaIndex[word] = i

print(aaIndex)
```

```
{'bear': 1, 'cap': 2, 'ball': 3, 'butterfly': 4, 'chirp': 5, 'come': 6, 'dance': 7, 'daddy': 8, 'mommy': 9, 'baby': 10, 'tee-hee': 11}

```

```python
# Out Of Vocabulary를 위한 OOV를 하나 생성하여, 
# 단어집합에 없는 단어는 OOV에 넣을 수 있는 코드를 작성 
aaIndex['OOV'] = len(aaIndex) + 1
print(aaIndex)
```

```
{'bear': 1, 'cap': 2, 'ball': 3, 'butterfly': 4, 'chirp': 5, 'come': 6, 'dance': 7, 'daddy': 8, 'mommy': 9, 'baby': 10, 'tee-hee': 11, 'OOV': 12}

```

```python
ess = []
for f in fs:
  es = []
  for w in f:
    try:
      es.append(aaIndex[w])
    except KeyError:
      es.append(aaIndex['OOV'])
  ess.append(es)
print(ess)
```

```
[[], [], [], [], [], [2], [2], [2, 2, 2], [], [], [], [], [], [3], [3], [3, 3, 3], [12, 12, 12, 12], [12, 12], [12, 12, 12, 12], [12, 12], [4, 4, 6, 12, 12, 12, 4, 6, 7], [12, 12, 12, 12, 12, 12, 12, 5, 5, 5, 12, 12, 7, 12, 12, 12, 12, 12, 12, 12, 8, 1, 9, 1, 10, 1, 8, 1, 12, 12, 9, 1, 12, 12, 10, 1, 12, 12, 11, 11]]

```

```python
# konlpy의 Okt를 이용해서 [나는 지금 테스트를 진행 중 입니다]라는 문장에 대한
# 형태소 토큰화를 진행한 후, 토큰마다 인덱스를 부여한 후에 
# 원-핫 벡터를 뽑아내는 함수를 작성하고, 
# 그 함수를 통해서 [테스트]라는 단어가 어떤 원-핫 벡터를 가지고 있는지 확인하는 코드를 작성

!pip install konlpy
```

```python
from konlpy.tag import Okt
okt = Okt()
wt = okt.morphs("나는 지금 테스트를 진행 중 입니다")
print(wt)
```

```
['나', '는', '지금', '테스트', '를', '진행', '중', '입니다']

```

```python
wi = {w : i for (i, w) in enumerate(wt)}
print(wi)
```

```
{'나': 0, '는': 1, '지금': 2, '테스트': 3, '를': 4, '진행': 5, '중': 6, '입니다': 7}

```

```python
def ohe(w, wi):
  ohVector = [0] * len(wi)
  index = wi[w]
  ohVector[index] = 1
  return ohVector

print(ohe('테스트', wi))
```

```
[0, 0, 0, 1, 0, 0, 0, 0]

```








